{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69638c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 692.7561 | Val Loss: 170.1409\n",
      "Validation loss increased. Stopping early and keeping best model.\n",
      "✅ Best model saved as audio_emotion_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Emotion labels\n",
    "labels = ['Angry', 'Disgusted', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Suprised']\n",
    "label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Dataset class\n",
    "class AudioEmotionDataset(Dataset):\n",
    "    def __init__(self, file_paths, sr=22050, max_len=5.0, n_mels=128):\n",
    "        self.file_paths = file_paths\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.file_paths[idx]\n",
    "        y, sr = librosa.load(path, sr=self.sr, duration=self.max_len)\n",
    "        if len(y) < int(self.max_len * sr):\n",
    "            y = np.pad(y, (0, int(self.max_len * sr) - len(y)))\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=self.n_mels)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_tensor = torch.tensor(mel_db).unsqueeze(0)  # [1, 128, T]\n",
    "\n",
    "        return mel_tensor.float(), torch.tensor(label)\n",
    "\n",
    "# Prepare stratified split file paths\n",
    "from collections import defaultdict\n",
    "all_file_paths = []\n",
    "dataset_path = \"elec378 sp25 dataset\"\n",
    "for label in labels:\n",
    "    folder = os.path.join(dataset_path, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".wav\"):\n",
    "            all_file_paths.append((os.path.join(folder, file), label_to_index[label]))\n",
    "\n",
    "by_label = defaultdict(list)\n",
    "for path, label in all_file_paths:\n",
    "    by_label[label].append((path, label))\n",
    "\n",
    "train_data, val_data = [], []\n",
    "for label, items in by_label.items():\n",
    "    train_split, val_split = train_test_split(items, test_size=0.2, random_state=42)\n",
    "    train_data.extend(train_split)\n",
    "    val_data.extend(val_split)\n",
    "\n",
    "train_dataset = AudioEmotionDataset(train_data)\n",
    "val_dataset = AudioEmotionDataset(val_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Dynamic CNN\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7, filters=[16, 32, 64], fc_dim=128, dropout=0.3):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, filters[0], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(filters[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(filters[0], filters[1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(filters[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(filters[1], filters[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(filters[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((4, 4))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[2] * 4 * 4, fc_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Train once function\n",
    "\n",
    "def train_one(model, train_loader, val_loader, epochs=5, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {total_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return total_loss, val_loss, model.state_dict()\n",
    "\n",
    "# Architecture search\n",
    "architectures = [\n",
    "     # Around best: 256, 0.2  \n",
    "    {\"filters\": [16, 32, 64], \"fc_dim\": 1098, \"dropout\": 0.25},\n",
    " \n",
    "     \n",
    "]\n",
    "\n",
    "results = []\n",
    "for arch in architectures:\n",
    "    print(\"Testing architecture:\", arch)\n",
    "    model = AudioCNN(num_classes=7, **arch)\n",
    "    train_loss, val_loss, weights = train_one(model, train_loader, val_loader, epochs=2)\n",
    "    results.append((arch, val_loss, weights))\n",
    "\n",
    "# Choose best architecture\n",
    "best_arch, best_val_loss, best_weights = min(results, key=lambda x: x[1])\n",
    "print(\"Best architecture:\", best_arch, \"with val loss:\", best_val_loss)\n",
    "\n",
    "# Retrain best architecture with early stopping\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, val_loader, max_epochs=20, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {epoch}/{max_epochs} - Train Loss: {total_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            print(\"Validation loss increased. Stopping early and keeping best model.\")\n",
    "            break\n",
    "\n",
    "    if best_model:\n",
    "        torch.save(best_model, \"audio_emotion_model.pth\")\n",
    "        print(\"✅ Best model saved as audio_emotion_model.pth\")\n",
    "\n",
    "# Final run\n",
    "final_model = AudioCNN(num_classes=7, **best_arch)\n",
    "train_with_early_stopping(final_model, train_loader, val_loader, max_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afb11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions to submission.csv!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Emotion labels (in same order as training)\n",
    "labels = ['Angry', 'Disgusted', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Suprised']\n",
    "index_to_label = {i: label for i, label in enumerate(labels)}\n",
    "best_arch = {\"filters\": [16, 32, 64], \"fc_dim\": 1098, \"dropout\": 0.25}  # slightly more\n",
    "# Load the trained model\n",
    "model = AudioCNN(num_classes=7, **best_arch)\n",
    "model.load_state_dict(torch.load(\"audio_emotion_model.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Test Dataset\n",
    "class TestAudioDataset(Dataset):\n",
    "    def __init__(self, test_dir, sr=22050, max_len=5.0, n_mels=128):\n",
    "        self.file_paths = []\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Sort files numerically: 1.wav, 2.wav, ..., 10.wav\n",
    "        for file in sorted(os.listdir(test_dir), key=lambda x: int(os.path.splitext(x)[0])):\n",
    "            if file.endswith(\".wav\"):\n",
    "                self.file_paths.append(os.path.join(test_dir, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        y, sr = librosa.load(path, sr=self.sr, duration=self.max_len)\n",
    "        if len(y) < int(self.max_len * sr):\n",
    "            y = np.pad(y, (0, int(self.max_len * sr) - len(y)))\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=self.n_mels)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_tensor = torch.tensor(mel_db).unsqueeze(0).float()  # [1, 128, T]\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        return mel_tensor, filename\n",
    "\n",
    "# Set up DataLoader\n",
    "test_path = \"elec378 sp25 dataset/Test\"  # <-- use your actual test path here\n",
    "test_dataset = TestAudioDataset(test_path)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Run inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mel_tensor, filename in test_loader:\n",
    "        mel_tensor = mel_tensor.to(device)\n",
    "        output = model(mel_tensor)\n",
    "        predicted_index = torch.argmax(output, dim=1).item()\n",
    "        predicted_emotion = index_to_label[predicted_index]\n",
    "        predictions.append((filename[0], predicted_emotion))\n",
    "\n",
    "# Create CSV\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"name\", \"emotion\"])\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Saved predictions to submission.csv!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
